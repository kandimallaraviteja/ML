{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Review Questions-I from MDSC-301(P)\n",
    "\n",
    "----------------------------------------------------------------\n",
    "Author: Ravi teja Kandimalla\n",
    "\n",
    "Date: September 07, 2022\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1. Which Linear Regression training algorithm can you use if you have\n",
    "a training set with millions of features?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "1. Batch Gradient Descent  \n",
    "1. Stochastic Gradient Descent  \n",
    "3. Mini-Batch Gradient\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. Suppose the features in your training set have very different scales.\n",
    "Which algorithms might suffer from this, and how? What can you\n",
    "do about it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient algorithms because different scaling could elongate the bowl shape curve and the computation time. Scaling the features or increasing learning rate will help to resolve this. Normal equations will not suffer highly.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.  Suppose you use Batch Gradient Descent and you plot the validation\n",
    "error at every epoch. If you notice that the validation error\n",
    "consistently goes up, what is likely going on? How can you fix this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means we have set-up higher learning rate for the algorithms and it's diverging it to other points. And Also training error goes up,  Decreasing the Alpha i.e. learning rate should work. If Training rate isn't going up, model may be overfitting and we can stop training for regularizing data.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. Is it a good idea to stop Mini-batch Gradient Descent immediately\n",
    "when the validation error goes up?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO, In Mini batcheWe only tend to stop the algorithm if no changes are seen for long time. We randomly selected examples and it may be possible to get validation error high. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Suppose you are using Polynomial Regression. You plot the learning\n",
    "curves and you notice that there is a large gap between the training\n",
    "error and the validation error. What is happening? What are three\n",
    "ways to solve this?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"gap\" is called overfitting if the training error is less and validation error piles up. We can reduce it by performing \n",
    "1. Regaularizaton with Lasso and Ridge Regression\n",
    "2. Reduce the polynomial degree \n",
    "3. feeding more training data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Suppose you are using Ridge Regression and you notice that the\n",
    "training error and the validation error are almost equal and fairly\n",
    "high. Would you say that the model suffers from high bias or high\n",
    "variance? Should you increase the regularization hyperparameter $\\alpha$\n",
    "or reduce it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sense that bias is high and thus, model is underfitting the model. We should be reducing the hyperparamter $\\alpha$.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q7. Why would you want to use:__\n",
    "   - Ridge Regression instead of plain Linear Regression (i.e., without any regularization)?\n",
    "   - Lasso instead of Ridge Regression?\n",
    "   - Elastic Net instead of Lasso?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "-  A model with perform with some regularization as it try to keep check on bias-Variance trade off. A simple model like linear regression will have limitations for any more changes apart from decreasing complexity in model.\n",
    "- Lasso will give upperhand by providing the method to perform automatic feature selection by dropping weights of most important features. It is able to force the coeffiecents to zero which can't be done in ridge regularization.\n",
    "- Elastic Net gives profits of both Lasso and ridge, making it more efficient. It's predicitve power is better than lasso, while still performing feature selection. \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.  Can you name four of the main challenges in Machine Learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quality of data\n",
    "- Insufficiency of data\n",
    "- Irrevelant Features\n",
    "- Under and Over fitting of Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. If your model performs great on the training data but generalizes\n",
    "poorly to new instances, what is happening? Can you name three\n",
    "possible solutions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means that overfitting of data. We can avoid this by interducing:\n",
    "1. feeding more training Data\n",
    "1. regualrization \n",
    "1. Cross validation\n",
    "1. Dimensionality reduction \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10. What is a test set, and why would you want to use it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset is build of unseen datapoints taken from original dataset apart from training dataset to check the accuracy of model after the training and know the model performance overall.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.  What is the purpose of a validation set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation dataset is taken from training dataset and model is checked on this after every epoch to give the unbiased evaluation of model which can help to early stop of training and tuning the hyperparamaters.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12. What are different loss functions? Exaplain their importance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Loss functions:\n",
    "1. Mean Squared Error \n",
    "    - $ MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2$\n",
    "    - Higher errors are penalized heavily than the smaller errors. Being a differential function, it is easier to calculate gradients.\n",
    "    \n",
    "  \n",
    "  \n",
    "2. Root Mean Squared Error \n",
    "    * $RMSE = \\sqrt{MSE}$\n",
    "    * Brings MSE to the same units of data under analysis.\n",
    "    \n",
    "  \n",
    "  \n",
    "3. Mean Absolute Error \n",
    "    * $MAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i-\\hat{y}_i|$\n",
    "    * preserves the same units of measurement as the data under analysis. MAE scores increases linearly with increases in errors and thus is much more interpretable than MSE.\n",
    "    \n",
    "  \n",
    "4. Hinge Loss \n",
    "    * $Hinge Loss = max(0, 1- y\\cdot\\hat{y})$\n",
    "    * It is most commonly employed to regularize soft margin support vector machines. \n",
    "    \n",
    "  \n",
    "  \n",
    "5. Logistic/Cross Entropy Loss \n",
    "    * leads to better probability estimation at the cost of accuracy.\n",
    "    * $L = -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot log(\\hat{y_i})$\n",
    "    \n",
    "    \n",
    "===>Thanks to latix\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13. Explain the following:\n",
    "    - Gradient descent\n",
    "    - Mini-batch gradient descent\n",
    "    - Batch gradient, and\n",
    "    - Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Batch Gradient Descent :**\n",
    ">> Averaging over all the gradients of training data for a single step. The training data is taken into consideration to take a single step. and then, mean gradient is used to update the parameters. This will give a smoothen curve later for __cost vs epoch__ graph because we are taking mean gradient in each epoch.\n",
    "***\n",
    "> **Stochastic Gradient Descent :**\n",
    ">> More the data, better the model. If data is on large scale, it's difficult to implement Batch Gradient descent. Here comes, Stochastic Gradient Descent or SGD. It will take single example in single epoch. This will be done for all the examples but randomly and weights will be updated simulanteously. The cost curve will fluctuate as it need not decrease everytime but will be good in long run.\n",
    "Run faster for Larger Datasets.\n",
    "***\n",
    "> **Mini Batch Gradient :**\n",
    ">> BGD runs smoothly for smaller datasets and converges to minima whereas SGD works good for larger datasets but vectorization can't be implemented as  it takes single output at a time. Thus we define mini-batches of fixed sizes which give advantages of both the variants.  \n",
    "Each epoch will train on mini-batch and calculate mean gradient and update the weights.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14. What is learning rate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is step size to be taken in each iteration. while finding minimum of a loss function in gradient descent algorithms.\n",
    "- Higher the $\\alpha$, higher chance of missing minima. \n",
    "- Lower the $\\alpha$, more the computation time\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15. Define the following terms. Explain their importance in the data analysis.**\n",
    "   - $R^2$\n",
    "   - Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $R^2$ : It's statistical measure to represnt the proportion of the variance for a dependent variable that's explanied by an indepenedent variable or variables in a regression model. few regressors addition, and it will increase no matter what the contribution. That's where we get Adj. $R^2$\n",
    ">>> $Formula   R^2 = 1 - \\frac{RSS}{TSS}$\n",
    "***\n",
    "> $Adjusted   R^2$ :It will add the penalty to the accuracy for those dummy variables who are not contibuting in the model significantly. We can observe with both that how the model is actually performing.\n",
    ">>>$Formula Adj. R^2 = 1- \\frac{RSS/(n-k)}{TSS/(n-1)}$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16. Explain One-Hot Encoding and Label Encoding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One-Hot Encoding:\n",
    ">> It is used for nominal ordered features which has no ordering sense but has different classes. It will add features equal to the classes present in the features. this will add dummy variables in the dataset.\n",
    "***\n",
    "> Label Encoding:\n",
    ">> It can used for ordinal categorical features which has specific inherit ordering sense. We can simply provide numbers to all classes present. \n",
    "Also known as Integer Encoding\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17. What are the assumption on Naive Bayes algorithm in classification?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes assumptions:\n",
    "\n",
    "- Probabilities for each class is either uniform. \n",
    "- likelihood probabilities are Gaussian.\n",
    "- All the features are independent.Thus p-dimensional class-conditional distributions can be factorised into a product of p univariate distributions.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18. What is the difference between classification and regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences are basically on the approches taken and the target variable defined.\n",
    "> __Classification :__ When the regressand is categorical variable and we need to classify based on the probablities of all classes present in it, classfications algorithms will soar. IT can also be seen as mapping function. It works well on unsupervised data.\n",
    "\n",
    "> __Regression :__ It predicts the best approximated continuous output value based on the features given as input.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19. How to ensure that the model is not overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to resolve the overfitting in the model.\n",
    "- Regularization - L1 or L2\n",
    "- Data Augmentation\n",
    "- Splitting the data into test and validation dataset\n",
    "- Decreasing the complexity by dropping features\n",
    "- Adding more training Data\n",
    "- Feature Selection\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20. List the main advantage of Naive Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses Bayesian technique and thus does not require much training data\n",
    "- It's better suited for categorical predictors than numerical variables\n",
    "- If the independence of features holds true, Navie Bayes can perform better than other models\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21. What you should do when your model is suffereing from:  \n",
    "    - Low bias and high variance?  \n",
    "    - High bias and low variance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Low Bias and High Variance:*\n",
    "\n",
    "   - Models that overfit have low bias and high variance.\n",
    "   - We can reduce the complexity of the model to get a good bias-variance trade off\n",
    "   - We can use Regularization techniques to reduce overfitting.\n",
    "   \n",
    "*High Bias and Low Variance:*\n",
    "\n",
    "   - Models that underfit have high bias and low variance.\n",
    "   - By interducing bias-variance trade off\n",
    "   - We can increase the number of features to overcome this.\n",
    "   - We can also do feature engineering.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22. What is the 'Naive' in the Naive Bayes Classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is called Naive Bayes because it assumes independence of all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q23. What is bias-variance tradeoff in Machine Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the tradeoff between model's ability to minimize bias and variance simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q24. Explain different trade-offs in Machine Learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias- Variance Tradeoff\n",
    "- Interpretability and Accuracy tradeoff\n",
    "- Precision Recall Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q25. What is cross-validation and how it is useful in traing ML models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a technique for evaluating ML models, where training is done on various subsets of the available input data and evaluating them on the complementary subset of the data.   \n",
    "Cross-validation can be used to detect overfitting. It can be useful when data is too small to split into training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
